{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f5f00dea",
      "metadata": {},
      "source": [
        "## Computer Vision Assignment\n",
        "### Instructions\n",
        "In this assignment, you will apply the computer vision concepts covered in the lesson to perform image classification using the Fashion MNIST dataset. The Fashion MNIST dataset consists of 60,000 28x28 grayscale images of 10 fashion categories.\n",
        "\n",
        "### Task: Build an Image Classifier\n",
        "1. Use the provided starter code to load and explore the Fashion MNIST dataset\n",
        "2. Preprocess the images using appropriate techniques (e.g., normalization, data augmentation)\n",
        "3. Build a CNN model to classify the images into one of the 10 classes\n",
        "4. Train your model and evaluate its performance\n",
        "5. Experiment with at least one technique to improve model performance (e.g., batch normalization, different pooling strategies, additional convolutional layers)\n",
        "6. Visualize and analyze your results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "20757abe",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\g_nan\\miniconda3\\envs\\dl\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import io\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')  # avoid GUI backend to prevent kernel crash\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from IPython.display import display, Image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5d8a9175",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define transformations (with augmentation: rotation and optional horizontal flip)\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "770b6b10",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the Fashion MNIST dataset\n",
        "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Classes in Fashion MNIST\n",
        "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f22d93ad",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set size: 60000\n",
            "Test set size: 10000\n"
          ]
        }
      ],
      "source": [
        "# Display after load: dataset sizes and sample training images\n",
        "print(f'Training set size: {len(train_dataset)}')\n",
        "print(f'Test set size: {len(test_dataset)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "56ff6ba6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# CNN model for Fashion MNIST (28x28 grayscale, 10 classes)\n",
        "# Improvement: Batch normalization after each conv layer (from lesson)\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(num_features=32)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(num_features=64)\n",
        "        self.fc1 = nn.Linear(in_features=64 * 7 * 7, out_features=512)\n",
        "        self.fc2 = nn.Linear(in_features=512, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleCNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3367d7e5",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            inputs, labels = data\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        print(f'Epoch {epoch + 1}, Loss: {avg_loss:.4f}')\n",
        "    print('Training finished')\n",
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels = data\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100.0 * correct / total\n",
        "    print(f'Accuracy of the network on the test images: {accuracy:.2f}%')\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4248681f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.4423\n",
            "Epoch 2, Loss: 0.3110\n",
            "Epoch 3, Loss: 0.2747\n",
            "Epoch 4, Loss: 0.2473\n",
            "Epoch 5, Loss: 0.2308\n",
            "Epoch 6, Loss: 0.2136\n",
            "Epoch 7, Loss: 0.2033\n",
            "Epoch 8, Loss: 0.1921\n",
            "Epoch 9, Loss: 0.1812\n",
            "Epoch 10, Loss: 0.1718\n",
            "Training finished\n",
            "Accuracy of the network on the test images: 91.23%\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "91.23"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Train the model (shows loss each epoch)\n",
        "train_model(model, train_loader, criterion, optimizer, num_epochs=10)\n",
        "\n",
        "# Evaluate and show final test accuracy\n",
        "evaluate_model(model, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9efae69f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted: Ankle boot   Pullover     Trouser      Trouser     \n"
          ]
        }
      ],
      "source": [
        "# Visualization: sample test images with predicted vs actual labels\n",
        "def imshow(img, ax):\n",
        "    img = img * 0.5 + 0.5  # unnormalize\n",
        "    npimg = img.detach().cpu().numpy()\n",
        "    ax.imshow(np.squeeze(npimg), cmap='gray')\n",
        "\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = next(dataiter)\n",
        "outputs = model(images)\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted:', ' '.join(f'{classes[predicted[j]]:12s}' for j in range(4)))\n",
        "\n",
        "fig = plt.figure(figsize=(8, 8))\n",
        "for idx in np.arange(9):\n",
        "    ax = fig.add_subplot(3, 3, idx + 1, xticks=[], yticks=[])\n",
        "    imshow(images[idx], ax)\n",
        "    ax.set_title(f'Predicted: {classes[predicted[idx]]}\\nActual: {classes[labels[idx]]}', fontsize=8)\n",
        "plt.tight_layout()\n",
        "buf = io.BytesIO()\n",
        "fig.savefig(buf, format='png', bbox_inches='tight')\n",
        "buf.seek(0)\n",
        "display(Image(data=buf.getvalue()))\n",
        "plt.close(fig)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
